# sppu-te-comp-sem2-assignments
SPPU TE (Comp) sem 2 Assignments

----------------------------------------------------------------------------------------------------------------------------------------
# Data Science and Big Data Analytics Lab

### GROUP A
**Assn1 - Data Wrangling I** <br>
Perform the following operations using Python on any open-source dataset (e.g., data.csv)
 1. Import all the required Python Libraries.
 2. Locate an open-source data from the web (e.g. https://www.kaggle.com). Provide a clear description of the data and its source (i.e., URL of the web site).
 3. Load the Dataset into pandas’ data frame.
 4. Data Preprocessing: check for missing values in the data using pandas isnull (), describe() function to get some initial statistics. Provide variable descriptions. Types of variables etc. Check the dimensions of the data frame.
 6. Data Formatting and Data Normalization: Summarize the types of variables by checking the data types (i.e., character, numeric, integer, factor, and logical) of the variables in the data set. If variables are not in the correct data type, apply proper type conversions.
 7. Turn categorical variables into quantitative variables in Python. <br>In addition to the codes and outputs, explain every operation that you do in the above steps and explain everything that you do to import/read/scrape the data set. 
 <br>


**Assn2 - Data Wrangling II** <br>
Create an “Academic performance” dataset of students and perform the following operations using Python.
 1. Scan all variables for missing values and inconsistencies. If there are missing values and/or inconsistencies, use any of the suitable techniques to deal with them.
 2. Scan all numeric variables for outliers. If there are outliers, use any of the suitable techniques to deal with them.
 3. Apply data transformations on at least one of the variables. The purpose of this transformation should be one of the following reasons: to change the scale for better understanding of the variable, to convert a non-linear relation into a linear one, or to decrease the skewness and convert the distribution into a normal distribution.<br>Reason and document your approach properly. 
 <br>
 
 
 **Assn3 - Descriptive Statistics - Measures of Central Tendency and variability** <br>
Perform the following operations on any open-source dataset (e.g., data.csv).
 1. Provide summary statistics (mean, median, minimum, maximum, standard deviation) for a dataset (age, income etc.) with numeric variables grouped by one of the qualitative (categorical) variable. For example, if your categorical variable is age groups and quantitative variable is income, then provide summary statistics of income grouped by the age groups. Create a list that contains a numeric value for each response to the categorical variable.
 2. Write a Python program to display some basic statistical details like percentile, mean, standard deviation etc. of the species of ‘Iris-setosa’, ‘Iris-versicolor’ and ‘Irisversicolor’ of iris.csv dataset.
<br>Provide the codes with outputs and explain everything that you do in this step.
<br>


**Assn4 - Data Visualization I** <br>
Create an “Academic performance” dataset of students and perform the following operations using Python.
 1. Use the inbuilt dataset 'titanic'. The dataset contains 891 rows and contains information about the passengers who boarded the unfortunate Titanic ship. Use the Seaborn library to see if we can find any patterns in the data.
 2. Write a code to check how the price of the ticket (column name: 'fare') for each passenger is distributed by plotting a histogram.
<br>The objective is to predict the value of prices of the house using the given features.
<br>
 
 
**Assn5 - Data Visualization II** <br>
Use the inbuilt dataset 'titanic' as used in the above problem. Plot a box plot for distribution of age with respect to each gender along with the information about whether they survived or not. (Column names: 'sex' and 'age')
<br>
 
 
 
**Assn6 - Data Visualization III** <br>
Download the Iris flower dataset or any other dataset into a DataFrame. (e.g., https://archive.ics.uci.edu/ml/datasets/Iris).
Scan the dataset and give the inference as:
 1. List down the features and their types (e.g., numeric, nominal) available in the dataset.
 2. Create a histogram for each feature in the dataset to illustrate the feature distributions.
 3. Create a box plot for each feature in the dataset. Compare distributions and identify outliers.
 <br>
 
 
 
**Assn7 - Text Analytics** <br>
 1. Extract Sample document and apply following document preprocessing methods: Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization
 2. Create representation of document by calculating Term Frequency and Inverse Document Frequency.
<br>
 
 
**Assn8 - Data Analytics I** <br>
Create a Linear Regression Model using Python/R to predict home prices using Boston Housing Dataset. The Boston Housing dataset contains information about various houses in Boston through different parameters. There are 506 samples and 14 feature variables in this dataset. 
<br>
 
 
**Assn9 - Data Analytics II** <br>
 1. Implement logistic regression using Python/R to perform classification on Social_Network_Ads.csv dataset.
 2. Compute Confusion matrix to find TP, FP, TN, FN, Accuracy, Error rate, Precision, Recall on the given dataset.
 <br>
 
 
 **Assn10 - Data Analytics III** <br>
 1. Implement Simple Naïve Bayes classification algorithm using Python/R on iris.csv dataset.
 2. Compute Confusion matrix to find TP, FP, TN, FN, Accuracy, Error rate, Precision, Recall on the given dataset.
<br>



### GROUP B - Big Data Analytics – JAVA/SCALA
**Assn11** <br>
Write a code in JAVA for a simple Word Count application that counts the number of occurrences of each word in a given input set using the Hadoop Map-Reduce framework on local-standalone set-up.
<br>



**Assn12** <br>
Locate dataset (e.g., sample_weather.txt) for working on weather data which reads the text input files and finds average for temperature, dew point and wind speed using the Hadoop Map-Reduce framework on local-standalone set-up.
<br>



**Assn13** <br>
Write a simple program in SCALA using Apache Spark framework.
<br>
<br>
-----------------------------------------------------------------------------------------------------------

# Laboratory Practice - II

### AI Assignments

**Assn1 - DFS, BFS** <br>
Implement depth first search algorithm and Breadth First Search algorithm, use an undirected graph and develop a recursive algorithm for searching all the vertices of a graph or tree data structure.
<br>


**Assn2 - A-star** <br>
Implement A Star Algorithm for any game search problem.
<br>


**Assn3 - Greedy** <br>
Implement Greedy search algorithm for any one of the following application:
 1. Selection Sort
 2. Minimum Spanning Tree
 3. Single-Source Shortest Path Problem
 4. Job Scheduling Problem
 5. Prim's Minimal Spanning Tree Algorithm
 6. Kruskal's Minimal Spanning Tree Algorithm
 7. Dijkstra's Minimal Spanning Tree Algorithm
<br>


**Assn4 - Constraint Satisfaction Problem** <br>
Implement a solution for a Constraint Satisfaction Problem using Branch and Bound and Backtracking for N-Queens problem or a graph coloring problem.
<br>


**Assn5 - ChatBot** <br>
Develop an elementary catboat for any suitable customer interaction application.
<br>


**Assn6 - Expert System** <br>
Implement Greedy search algorithm for any one of the following application:
 1. Information management
 2. Hospitals and medical facilities
 3. Help desks management
 4. Employee performance evaluation
 5. Stock market trading
<br>
